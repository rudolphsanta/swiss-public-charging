---
title: "Swiss Public Charging Data Analysis"
output: html_document
date: "2024-11-04"
---

```{r setup, include=FALSE}
library(pxR)
library(dplyr)
library(tidyverse)

```


```{r charging point details}
CH_EVSE_details <- read.csv("M:/Rudolph/R-Projects/swiss-public-charging/data/EVSE_details_2024-10-04h.csv") %>%
  mutate(Power_kW = as.integer(sub("^(\\d+).*", "\\1", ChargingFacilities)))

CH_EVSE_details_short <- CH_EVSE_details %>%
  select(EvseID, ChargingStationId, ChargingFacilities, Power_kW, Accessibility, City, GeoCoordinates)

```


```{r october data}
charge.points.data <- read.csv("M:/Rudolph/0-Datasets/Switzerland/Swiss-chargers.csv")
```


```{r function to convert charging availability tables - monthly data}

EVSE_processing <- function(csv_file, merged_object = NULL, id_col = "EvseID") { #file path as a string input
  # Read the csv file into a dataframe object
  my.df <- read.csv(csv_file)
  
  # Convert the availability statuses into factors (to save storage space)
  factor_cols <- 2:dim(my.df)[2]
  my.df[ , factor_cols] <- lapply(my.df[ , factor_cols],factor)

  # (Optional) Merge with an existing object
  if(!is.null(merged_object)) {
    result.df <- merge(merged_object, my.df, by = id_col, all = TRUE)
    return(result.df) #return a merged dataframe if one is defined
  }
  return(my.df) #return the single processed data frame
}

```

```{r function to cycle through files in a folder - monthly data}
read_csvs <- function(main_dir = "M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data", start_f = 1, n_files = 'All') {
  # Get list of sub-directories in the main directory
  # subdirs <- list.dirs(main_dir, full.names = TRUE, recursive = FALSE)
  
  # Get list of files in the main directory
  if(n_files == 'All')  file_list <- list.files(main_dir)
  # to do a subset of the files
  else {
    end_f = start_f + n_files - 1
    file_list <- list.files(main_dir)[start_f:end_f]
  }
  
  df_statuses <- NULL #initiate NULL for the dataframe
  
  # Loop through each sub directory
  for (file in file_list) {
    start_time <- Sys.time()

    # Create the full path to the CSV file
    csv_file_path <- file.path(main_dir, file)
    
    if(!file.exists(csv_file_path)) next #if the file does not exist, then go to the next one.
    
    if(is.null(df_statuses)) { #the first time this is run, df_statuses will be NULL
      # Read and process the csv
      df_statuses <- EVSE_processing(csv_file_path)
    } else {
      # Read, process, and merge the csv with existing ones
      df_statuses <- EVSE_processing(csv_file_path, merged_object = df_statuses)
    }
    end_time <- Sys.time()

    execution_time <- end_time - start_time

    cat("Execution time was", as.numeric(execution_time, units = "secs"), "s for this iteration.\n")

  }
  
  return(df_statuses)
}

```

```{r read and subset csvs}

read_and_filter_csvs <- function(main_dir = "M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data", 
                                 weekday = 1, 
                                 n_files = 'All') {
  # Get list of files in the main directory
  if(n_files == 'All')  file_list <- list.files(main_dir)
  # to do a subset of the files
  else {
    end_f = start_f + n_files - 1
    file_list <- list.files(main_dir)[start_f:end_f]
  }
  
  df_statuses <- NULL #initiate NULL for the dataframe
  
  # Loop through each sub directory
  for (file in file_list) {
    start_time <- Sys.time()

    # Create the full path to the CSV file
    csv_file_path <- file.path(main_dir, file)
    
    if(!file.exists(csv_file_path)) next #if the file does not exist, then go to the next one.
    
    if(is.null(df_statuses)) { #the first time this is run, df_statuses will be NULL
      # Read and process the csv
      df_statuses <- EVSE_processing(csv_file_path)
    } else {
      # Read, process, and merge the csv with existing ones
      df_statuses <- EVSE_processing(csv_file_path, merged_object = df_statuses)
    }
    end_time <- Sys.time()

    execution_time <- end_time - start_time

    cat("Execution time was", as.numeric(execution_time, units = "secs"), "s for this iteration.\n")

  }
  
  return(df_statuses)
}
```


```{r create joined df with all availability statuses - chunked method}
start_time <- Sys.time()
EVSE_partial.1a <- read_csvs(start_f = 1, n_files = 2)
EVSE_partial.1b <- read_csvs(start_f = 3, n_files = 2)
EVSE_partial.A <- merge(EVSE_partial.1a, EVSE_partial.1b, by = 'EvseID', all = TRUE)
execution_time <- Sys.time() - start_time
cat("Execution time was", as.numeric(execution_time, units = "secs"), "s for 4 files.\n")
print(dim(EVSE_partial.A))
```
```{r create joined df with all availability statuses - running method}
start_time <- Sys.time()
EVSE_partial.B <- read_csvs(start_f = 1, n_files = 4)
execution_time <- Sys.time() - start_time
cat("Execution time was", as.numeric(execution_time, units = "mins"), "min for 4 files.\n")
print(dim(EVSE_partial.B))
```
```{r create one wide data frame for the whole dataset - chunked method step 1}
file_list <- list.files("M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data")
num_files <- length(file_list)
files_in_partial <- 2
partials_in_chunk <- 2
files_in_chunk <- files_in_partial * partials_in_chunk

iterations <- ceiling(num_files/(files_in_chunk))
i <- 5
for(i in 2:iterations) {
  # long execution
  start_time <- Sys.time()
  
  partial_a_start <- (files_in_chunk*(i-1)) + i
  partial_b_start <- partial_a_start + files_in_partial
  
  
  EVSE_partial.a <- read_csvs(start_f = partial_a_start, n_files = files_in_partial)
  EVSE_partial.b <- read_csvs(start_f = partial_b_start, n_files = files_in_partial)
  
  
  EVSE_partial.result <- merge(EVSE_partial.a, EVSE_partial.b, by.x = 'EvseID', all = TRUE)
  obj_name <- paste("EVSE_partial", ".", i, sep = "")
  execution_time <- Sys.time() - start_time
  cat("Execution time was", as.numeric(execution_time, units = "mins"), "s for 4 files.\n")
  assign(obj_name,EVSE_partial.result) 
  
  #save the object
  filepath <- file.path("M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data", paste0(obj_name, ".csv"))
  write.csv(EVSE_partial.result, filepath)
  
  rm(EVSE_partial.a,EVSE_partial.b,EVSE_partial.result)
  gc()
}
```


```{r create one wide data frame for the whole dataset - chunked method step 2}
EVSE_partial_1_2 <- merge(EVSE_partial.1, EVSE_partial.2, by = 'EvseID', all = TRUE)
rm(EVSE_partial.1, EVSE_partial.2)
gc()

EVSE_partial_3_4 <- merge(EVSE_partial.3, EVSE_partial.4, by = 'EvseID', all = TRUE)
rm(EVSE_partial.3, EVSE_partial.4)
gc()

EVSE_partial_5_6 <- merge(EVSE_partial.5, EVSE_partial.6, by = 'EvseID', all = TRUE)
rm(EVSE_partial.5, EVSE_partial.6)
gc()


EVSE_df <- merge(EVSE_partial_1_2, EVSE_partial_3_4, by = 'EvseID', all = TRUE)
rm(EVSE_partial_1_2, EVSE_partial_3_4)
gc()

EVSE_df <- merge(EVSE_df, EVSE_partial_5_6, by = 'EvseID', all = TRUE)
rm(EVSE_partial_5_6)
gc()

write.csv(EVSE_df, "M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data/EVSE_FULL.csv")



```


# Parallel Setup
```{r chunked execution in parallel setup}
file_list <- list.files("M:/Rudolph/0-Datasets/Switzerland/Jan2022-Sep2024_charging-data/Processed-data")
num_files <- length(file_list)
files_in_chunk <- 2
iterations <- ceiling(num_files/files_in_chunk)

```

```{r parallel chunked execution - working}
library(future)
library(future.apply)
library(parallel)

cores <- detectCores() - 2 #max cores available. leave 2 cores unused
if(cores < iterations) iterations <- cores

plan(multisession, workers = iterations)

file_pairs <- list()

```


#### Adding columns to processed charging dataset
```{r merge power level of each charger}

EVSE_df <- merge(EVSE_partial.1, CH_EVSE_details_short[ , c('EvseID','Power_kW','City')], by = 'EvseID', all.x = TRUE)

EVSE_df <- EVSE_df %>%
  relocate(City, .after = EvseID) %>%
  relocate(Power_kW, .after = EvseID)
```

```{r cleaning - remove CPs (rows) with no availability data at all}

EVSE_df 

```


```{r segment by power level}
# summary(EVSE_df$Power_kW)
EVSE_lowP <- EVSE_df %>%
  filter(Power_kW <= 22)

EVSE_medP <- EVSE_df %>%
  filter(Power_kW <= 100 & Power_kW > 22)

EVSE_highP <- EVSE_df %>% 
  filter(Power_kW > 100)
```

```{r Utilization rate}

Util_rate <- function(df_input) { #takes the df object from function "read_csvs()" as the input
  df_util <- data.frame(timestamp = NA, year = NA, month = NA, day = NA, weekday = NA, hour = NA, minute = NA, occupied = NA, available = NA, unknown = NA, service = NA, NA_ = NA, total = NA, utilization = NA)
  for(col in colnames(df_input)) {
    if (!grepl("^S_", col)) next
    num_used <- sum(df_input[ ,col] == "Occupied", na.rm = TRUE) #number of occupied CPs
    num_available <- sum(df_input[ ,col] == "Available", na.rm = TRUE) #number of available CPs
    num_unknown <- sum(df_input[ ,col] == "Unknown", na.rm = TRUE) #number of unknown CPs
    num_service <- sum(df_input[ ,col] == "OutOfService", na.rm = TRUE) #number of out of service CPs
    num_NA <- sum(is.na(df_input[ ,col]), na.rm = TRUE) 
    tot_num <- length(df_input[ ,col])
    
    utilization_rate <- num_used/(num_used + num_available)
    
    #convert column name to a datetime object
    datetime_string <- sub("S_","",col)
    datetime_object <- ymd_hms(gsub("\\.", ":", datetime_string), tz = "Europe/Zurich")
    
    #record the data in a new results dataframe
    row_util <- data.frame(timestamp = datetime_object,
                           year = year(datetime_object), 
                           month = month(datetime_object),
                           day = day(datetime_object),
                           weekday = wday(datetime_object),
                           hour = hour(datetime_object),
                           minute = round(minute(datetime_object)/5)*5,
                           occupied = num_used, 
                           available = num_available, 
                           unknown = num_unknown, 
                           service = num_service,
                           NA_ = num_NA,
                           total = tot_num, 
                           utilization = utilization_rate)
    
    #bind with the large df
    df_util <- rbind(df_util, row_util)
  }
  return(df_util)
}

```

```{r Utilization rate values - by power level}
#takes some time to run

EVSE_util_lowP <- Util_rate(EVSE_lowP)

EVSE_util_medP <- Util_rate(EVSE_medP)

EVSE_util_highP <- Util_rate(EVSE_highP)

EVSE_util_ovr <- Util_rate(EVSE_df)

```

```{r}
summary(EVSE_util_ovr)

plot(x = EVSE_util_ovr$hour, y = EVSE_util_ovr$utilization*100, 
     ylim = c(0,20), ylab = "Utilization [%]", xlab = "Hour", 
     col = 'black', pch = 19, cex = 0.8)
```

```{r function to get certain parameters}
Subset_EVSE <- function(df_input, year.f = NULL, month.f = NULL, day.f = NULL, weekday.f = NULL, hour.f = NULL) {
  df_result <- df_input
  
  if(!is.null(year.f)) {df_result <- filter(df_result, year == year.f)}
  if(!is.null(month.f)) {df_result <- filter(df_result, month == month.f)}
  if(!is.null(day.f)) {df_result <- filter(df_result, day == day.f)}
  if(!is.null(weekday.f)) {df_result <- filter(df_result, weekday == weekday.f)}
  if(!is.null(hour.f)) {df_result <- filter(df_result, hour == hour.f)}
  
  return(df_result)
}

Get_CI <- function(df_input, col_name = "utilization", z_score = 1.96, clean.na = TRUE) {
  observations <- df_input[col_name]
  
  if(clean.na == TRUE)  observations <- observations[!is.na(observations)]
  
  sample_mean <- mean(observations)
  sample_sd <- sd(observations)
  sample_size <- length(observations)
  sample_min <- min(observations)
  sample_max <- max(observations)
  
  sample_median <- median(observations)
  
  std_err <- sample_sd/ sqrt(sample_size)
  
  lower_bound <- sample_mean - (z_score * std_err)
  upper_bound <- sample_mean + (z_score * std_err)
  
  
  return(list("lower_bound" = lower_bound,
              "mean" = sample_mean,
              "upper_bound" = upper_bound,
              "min" = sample_min,
              "max" = sample_max))
}
```

```{r sandbox}
filter(EVSE_util_wkday, !is.na("utilization"))

undebug(Get_CI)
Weekday.CI <- Get_CI(EVSE_util_wkday)
```


```{r weedays}
EVSE_util_wkday <- EVSE_util_ovr %>%
  filter(weekday <= 5)

h = 0
#get the confidence interval for each hour
for(h in 0:23) {
  this.df <- Subset_EVSE(EVSE_util_wkday, hour.f = h)
  
  this.CI <- Get_CI(this.df)
  
  result.df <- data.frame(hour = h, 
                          lower_bound = this.CI$lower_bound,
                          mean = this.CI$mean,
                          upper_bound = this.CI$upper_bound,
                          min = this.CI$min,
                          max = this.CI$max)
  
  if(h == 0) {
    result <- result.df
  } else {
    result <- rbind(result, result.df)
    }
}

#visualizations
result

plot(x = EVSE_util_wkday$hour, y = EVSE_util_wkday$utilization*100, 
     ylim = c(0,20), ylab = "Utilization [%]", xlab = "Hour", 
     col = 'black', pch = 19, cex = 0.8)

plot(result$hour, result$mean*100, type = 'l', col = 'black', 
     xlab = "hour", ylab = "utilization [%]", ylim = c(0,20),
     main = "Weekdays")
lines(result$hour, result$lower_bound*100, type = 'l', col = 'blue')
lines(result$hour, result$upper_bound*100, type = 'l', col = 'blue')
lines(result$hour, result$min*100, type = 'l', col = 'red')
lines(result$hour, result$max*100, type = 'l', col = 'red')

```
```{r}
hist(filter(result, hour = 10))
```

```{r clean data}
EVSE_util_df_cleaned <- EVSE_util_df %>%
  filter(unknown < dim(EVSE_util_df)[1] * 0.1) %>% #remove instances where 'unknown' CPs are too high, this is likely a data collection error
  merge(Charger_df, Status_df, by = "EvseID", all = TRUE)

```

```{r plot utilization}
plot(x = as.POSIXlt(EVSE_util_df_cleaned$timestamp), y = EVSE_util_df_cleaned$utilization, pch = 19,
     ylab = "Utilization Rate", xlab = "Date", ylim = c(0,0.25))

```
```{r filter for observations}

status_filter <- function(data, )

```

```{r EVSE details}

Power_demand <- function(Charger_df, Status_df) {
  Charger_df <- Charger_df %>%
    select(EvseID, Power_kW)
  
  # Add the power demand column to the status data frame
  Power_status_df <- merge(Charger_df, Status_df, by = "EvseID", all = TRUE)
  
  # convert "occupied" into the power level for all the status columns
 for(col in 3:dim(Power_status_df)[2]) {
   Power_status_df[ , col] <- Power_status_df[ , "Power_kW"] * as.numeric(Power_status_df[ , col] == "Occupied")
 }
  return(Power_status_df) 
}

```

```{r convert statuses into power level demands}
EVSE_df <- Power_demand(CH_EVSE_details_short, EVSE_partial.B)
```


```{r clean power status}
Power_status_df_cleaned <- Power_status_df %>%
  filter(!is.na(Power_kW))
```


```{r power level}
Power_level <- function(df_input, filters = NULL) { #takes the df object from function "Power_demand()" as the input
  df_power <- data.frame(timestamp = NA, year = NA, month = NA, day = NA, weekday = NA, hour = NA, minute = NA, power = NA)
  for(col in colnames(df_input[-c(1:2)])) {
    power_dem <- sum(df_input[ , col], na.rm = TRUE) #gets the total power level
    
    #convert column name to a datetime object
    datetime_string <- sub("S_","",col)
    datetime_object <- ymd_hms(gsub("\\.", ":", datetime_string), tz = "Europe/Zurich")
    
    #record the data in a new results dataframe
    row_pwr <- data.frame(timestamp = datetime_object,
                           year = year(datetime_object), 
                           month = month(datetime_object),
                           day = day(datetime_object),
                           weekday = wday(datetime_object),
                           hour = hour(datetime_object),
                           minute = round(minute(datetime_object)/5)*5,
                           power = power_dem)
    
    #bind with the large df
    df_power <- rbind(df_power, row_pwr)
  }
  return(df_power)
}

```

```{r power level data}
#takes time to run
Power_results <- Power_level(Power_status_df_cleaned)
```
```{r power level data cleaned}
Power_results_cleaned <- Power_results %>%
  filter(power > 0)

```


```{r plot power}
plot(x = as.POSIXlt(Power_results_cleaned$timestamp), y = Power_results_cleaned$power/1000, pch = 19,
     ylab = "Power Demand [MW]", xlab = "Date", ylim = c(0,20))
```

