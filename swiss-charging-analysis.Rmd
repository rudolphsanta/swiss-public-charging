---
title: "Swiss Public Charging Data Analysis"
output: html_document
date: "2024-11-04"
---

```{r setup, include=FALSE}
library(pxR)
library(dplyr)
library(tidyverse)

```


```{r charging data folder location}
monthly_chg_files <- "C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data"
chunked_chg_files <- "C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1"
```

```{r charging point details}
CH_EVSE_details <- read.csv("M:/Rudolph/R-Projects/swiss-public-charging/data/EVSE_details_2024-10-04h.csv") %>%
  mutate(Power_kW = as.integer(sub("^(\\d+).*", "\\1", ChargingFacilities)))

CH_EVSE_details_short <- CH_EVSE_details %>%
  select(EvseID, ChargingStationId, ChargingFacilities, Power_kW, Accessibility, City, GeoCoordinates)

```
```{r summarise charging point dataset}
summary(CH_EVSE_details_short$Power_kW)
hist(CH_EVSE_details_short$Power_kW, breaks = "FD", xlab = "Charge Point Power [kW]", main = "")
boxplot(CH_EVSE_details_short$Power_kW)
```


```{r function to convert charging availability tables - monthly data}

EVSE_processing <- function(csv_file, merged_object = NULL, id_col = "EvseID") { #file path as a string input
  # Read the csv file into a dataframe object
  my.df <- read.csv(csv_file)
  
  # Convert the availability statuses into factors (to save storage space)
  factor_cols <- 2:dim(my.df)[2]
  my.df[ , factor_cols] <- lapply(my.df[ , factor_cols],factor)

  # (Optional) Merge with an existing object
  if(!is.null(merged_object)) {
    result.df <- merge(merged_object, my.df, by = id_col, all = TRUE)
    return(result.df) #return a merged dataframe if one is defined
  }
  return(my.df) #return the single processed data frame
}

```

```{r function to cycle through files in a folder - monthly data}
read_csvs <- function(main_dir = monthly_chg_files, start_f = 1, n_files = 'All') {
  # Get list of sub-directories in the main directory
  # subdirs <- list.dirs(main_dir, full.names = TRUE, recursive = FALSE)
  
  # Get list of files in the main directory
  if(n_files == 'All')  file_list <- list.files(main_dir)
  # to do a subset of the files
  else {
    end_f = start_f + n_files - 1
    file_list <- list.files(main_dir)[start_f:end_f]
  }
  
  df_statuses <- NULL #initiate NULL for the dataframe
  
  # Loop through each sub directory
  for (file in file_list) {
    start_time <- Sys.time()

    # Create the full path to the CSV file
    csv_file_path <- file.path(main_dir, file)
    
    if(!file.exists(csv_file_path)) next #if the file does not exist, then go to the next one.
    
    if(is.null(df_statuses)) { #the first time this is run, df_statuses will be NULL
      # Read and process the csv
      df_statuses <- EVSE_processing(csv_file_path)
    } else {
      # Read, process, and merge the csv with existing ones
      df_statuses <- EVSE_processing(csv_file_path, merged_object = df_statuses)
    }
    end_time <- Sys.time()

    execution_time <- end_time - start_time

    cat("Execution time was", as.numeric(execution_time, units = "secs"), "s for this iteration.\n")

  }
  
  return(df_statuses)
}

```




```{r function to read in csvs}
csv_to_df <- function(file) {
  result <- read.csv(file, as.is = "EvseID")
  
  # Find the position of "EvseID" column
  evse_col <- which(names(result) == "EvseID")

  # Keep columns starting from "EvseID"
  result <- result[, evse_col:ncol(result)]
  
  return(result)
}

```

```{r to read the "EVSE_partial" datasets into dfs - IF NEEDED}
EVSE_partial.1 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.1.csv")
EVSE_partial.2 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.2.csv")
EVSE_partial.3 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.3.csv")
EVSE_partial.4 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.4.csv")
EVSE_partial.5 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.5.csv")
EVSE_partial.6 <- csv_to_df("C:/Users/santar_r/Documents/Rudolph_local/Datasets/Switzerland/Processed-data/EVSE_partial_step-1/EVSE_partial.6.csv")

```



#### Adding columns to processed charging dataset
```{r function to merge power level of each charger}
merge_power_location <- function(EVSE_partial_df) {
  EVSE_df <- merge(EVSE_partial_df, CH_EVSE_details_short[ , c('EvseID','Power_kW','City')], by = 'EvseID', all.x = TRUE)

  EVSE_df <- EVSE_df %>%
    relocate(City, .after = EvseID) %>%
    relocate(Power_kW, .after = EvseID)
  
  return(EVSE_df)
}

```


```{r add charge point data (power and location) to the partial dfs}
EVSE_df.1 <- merge_power_location(EVSE_partial.1)
EVSE_df.2 <- merge_power_location(EVSE_partial.2)
EVSE_df.3 <- merge_power_location(EVSE_partial.3)
EVSE_df.4 <- merge_power_location(EVSE_partial.4)
EVSE_df.5 <- merge_power_location(EVSE_partial.5)
EVSE_df.6 <- merge_power_location(EVSE_partial.6)

```

```{r function to get the utilization rate of each collected timestamp}
availability_summary <- function(df_input) { #takes the df object from function "read_csvs()" as the input
  # df_util <- data.frame(timestamp = NA, year = NA, month = NA, day = NA, weekday = NA, hour = NA, minute = NA, occupied = NA, available = NA, unknown = NA, service = NA, NA_ = NA, total = NA, utilization = NA)
  first <- TRUE
  for(col in colnames(df_input)) {
    if (!grepl("^S_", col)) next
    num_used <- sum(df_input[ ,col] == "Occupied", na.rm = TRUE) #number of occupied CPs
    num_available <- sum(df_input[ ,col] == "Available", na.rm = TRUE) #number of available CPs
    num_unknown <- sum(df_input[ ,col] == "Unknown", na.rm = TRUE) #number of unknown CPs
    num_service <- sum(df_input[ ,col] == "OutOfService", na.rm = TRUE) #number of out of service CPs
    num_NA <- sum(is.na(df_input[ ,col]), na.rm = TRUE) 
    tot_num <- length(df_input[ ,col])
    utilization_rate <- num_used/(num_used + num_available)
    
    #convert column name to a datetime object
    datetime_string <- sub("S_","",col)
    datetime_object <- ymd_hms(gsub("\\.", ":", datetime_string), tz = "Europe/Zurich")
    
    #record the data in a new results dataframe
    row_util <- data.frame(timestamp = datetime_object,
                           year = year(datetime_object), 
                           month = month(datetime_object),
                           day = day(datetime_object),
                           weekday = wday(datetime_object),
                           hour = hour(datetime_object),
                           minute = round(minute(datetime_object)/5)*5,
                           occupied = num_used, 
                           available = num_available, 
                           unknown = num_unknown, 
                           service = num_service,
                           NA_ = num_NA,
                           total = tot_num, 
                           utilization = utilization_rate)
    
    #make sure specific columns are integers
    int_cols <- c("year","month","day","weekday","hour","minute","occupied","available","unknown","service","NA_","total")
    row_util[ ,int_cols] <- lapply(row_util[ ,int_cols], as.integer)
    
    #bind with the large df
    if(first == TRUE) { #if this is the first row of the df
      df_util <- row_util
      first <- FALSE 
    } else {
      df_util <- rbind(df_util, row_util)
    }
    
  }
  return(df_util)
}

```


```{r SANDBOX}
EVSE_util.1 <- availability_summary(EVSE_df.1[ , 1:1000])

EVSE_util.1.winter <- EVSE_util.1 %>%
  filter(month %in% c(12,1,2))

summary(EVSE_util.1$month)
```

### Utilization rate curves of each day type
```{r get utilization rate for all times in each day type}
df_list <- c("EVSE_df.2","EVSE_df.3","EVSE_df.4","EVSE_df.5","EVSE_df.6") #include more if there are other datasets included now

#NOTE: If you want to subset by something else (power level, location, etc) that must be done before this step.

for(df in 1:length(df_list)) {
  this_df <- get(df_list[df])
  this_df <- availability_summary(this_df) #get the utilization and time details from this partial dataset
  #check
  leftover_rows <- nrow(this_df)
  
  #Note: Seasonal boundary months defined the same as in STEM-E
  #winter
  win_df <- this_df %>%
    filter(month %in% c(11,12,1))
  
  if(!exists("win_wk_util")) {
    win_wk_util <- filter(win_df, weekday %in% c(1,2,3,4,5))
    leftover_rows <- leftover_rows - nrow(win_wk_util)
  } else {
    this_util <- filter(win_df, weekday %in% c(1,2,3,4,5))
    win_wk_util <- rbind(win_wk_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("win_sa_util")) {
    win_sa_util <- filter(win_df, weekday == 6)
    leftover_rows <- leftover_rows - nrow(win_sa_util)
  } else {
    this_util <- filter(win_df, weekday == 6)
    win_sa_util <- rbind(win_sa_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("win_su_util")) {
    win_su_util <- filter(win_df, weekday == 7)
    leftover_rows <- leftover_rows - nrow(win_su_util)
  } else {
    this_util <- filter(win_df, weekday == 7)
    win_su_util <- rbind(win_su_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  #spring
  spg_df <- this_df %>%
    filter(month %in% c(2,3,4))

  if(!exists("spg_wk_util")) {
    spg_wk_util <- filter(spg_df, weekday %in% c(1,2,3,4,5))
    leftover_rows <- leftover_rows - nrow(spg_wk_util)
  } else {
    this_util <- filter(spg_df, weekday %in% c(1,2,3,4,5))
    spg_wk_util <- rbind(spg_wk_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("spg_sa_util")) {
    spg_sa_util <- filter(spg_df, weekday == 6)
    leftover_rows <- leftover_rows - nrow(spg_sa_util)
  } else {
    this_util <- filter(spg_df, weekday == 6)
    spg_sa_util <- rbind(spg_sa_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("spg_su_util")) {
    spg_su_util <- filter(spg_df, weekday == 7)
    leftover_rows <- leftover_rows - nrow(spg_su_util)
  } else {
    this_util <- filter(spg_df, weekday == 7)
    spg_su_util <- rbind(spg_su_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  #summer
  sum_df <- this_df %>%
    filter(month %in% c(5,6,7))
  
  if(!exists("sum_wk_util")) {
    sum_wk_util <- filter(sum_df, weekday %in% c(1,2,3,4,5))
    leftover_rows <- leftover_rows - nrow(sum_wk_util)
  } else {
    this_util <- filter(sum_df, weekday %in% c(1,2,3,4,5))
    sum_wk_util <- rbind(sum_wk_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("sum_sa_util")) {
    sum_sa_util <- filter(sum_df, weekday == 6)
    leftover_rows <- leftover_rows - nrow(sum_sa_util)
  } else {
    this_util <- filter(sum_df, weekday == 6)
    sum_sa_util <- rbind(sum_sa_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("sum_su_util")) {
    sum_su_util <- filter(sum_df, weekday == 7)
    leftover_rows <- leftover_rows - nrow(sum_su_util)
  } else {
    this_util <- filter(sum_df, weekday == 7)
    sum_su_util <- rbind(sum_su_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  #fall
  fal_df <- this_df %>%
    filter(month %in% c(8,9,10))
  
  if(!exists("fal_wk_util")) {
    fal_wk_util <- filter(fal_df, weekday %in% c(1,2,3,4,5))
    leftover_rows <- leftover_rows - nrow(fal_wk_util)
  } else {
    this_util <- filter(fal_df, weekday %in% c(1,2,3,4,5))
    fal_wk_util <- rbind(fal_wk_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("fal_sa_util")) {
    fal_sa_util <- filter(fal_df, weekday == 6)
    leftover_rows <- leftover_rows - nrow(fal_sa_util)
  } else {
    this_util <- filter(fal_df, weekday == 6)
    fal_sa_util <- rbind(fal_sa_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  if(!exists("fal_su_util")) {
    fal_su_util <- filter(fal_df, weekday == 7)
    leftover_rows <- leftover_rows - nrow(fal_su_util)
  } else {
    this_util <- filter(fal_df, weekday == 7)
    fal_su_util <- rbind(fal_su_util,this_util)
    leftover_rows <- leftover_rows - nrow(this_util)
  }
  
  print(leftover_rows)
}


```

```{r}
sum_su_util
```



```{r segment by power level}
# summary(EVSE_df$Power_kW)
EVSE_lowP <- EVSE_df %>%
  filter(Power_kW <= 22)

EVSE_medP <- EVSE_df %>%
  filter(Power_kW <= 100 & Power_kW > 22)

EVSE_highP <- EVSE_df %>% 
  filter(Power_kW > 100)

EVSE_unknownP <- EVSE_df %>%
  filter(is.na(Power_kW))
```


```{r Utilization rate values - by power level}
#takes some time to run

EVSE_util_lowP <- Util_rate(EVSE_lowP)

# EVSE_util_medP <- Util_rate(EVSE_medP)

# EVSE_util_highP <- Util_rate(EVSE_highP)

EVSE_util_ovr <- Util_rate(EVSE_df)


```

```{r}
summary(EVSE_util_ovr)

plot(x = EVSE_util_ovr$hour, y = EVSE_util_ovr$utilization*100, 
     ylim = c(0,20), ylab = "Utilization [%]", xlab = "Hour", 
     col = 'black', pch = 19, cex = 0.8)

hist(filter(EVSE_util_ovr, hour == 5)$utilization)

summary(EVSE_util_lowP)

plot(x = EVSE_util_lowP$hour, y = EVSE_util_lowP$utilization*100, 
     ylim = c(0,20), ylab = "Utilization [%]", xlab = "Hour", 
     col = 'black', pch = 19, cex = 0.8)

hist(filter(EVSE_util_lowP, hour == 5)$utilization)
```

```{r function to get certain parameters}
Subset_EVSE <- function(df_input, year.f = NULL, month.f = NULL, day.f = NULL, weekday.f = NULL, hour.f = NULL) {
  df_result <- df_input
  
  if(!is.null(year.f)) {df_result <- filter(df_result, year == year.f)}
  if(!is.null(month.f)) {df_result <- filter(df_result, month == month.f)}
  if(!is.null(day.f)) {df_result <- filter(df_result, day == day.f)}
  if(!is.null(weekday.f)) {df_result <- filter(df_result, weekday == weekday.f)}
  if(!is.null(hour.f)) {df_result <- filter(df_result, hour == hour.f)}
  
  return(df_result)
}

Get_CI <- function(df_input, col_name = "utilization", z_score = 1.96, clean.na = TRUE) {
  observations <- df_input[col_name]
  
  if(clean.na == TRUE)  observations <- observations[!is.na(observations)]
  
  sample_mean <- mean(observations)
  sample_sd <- sd(observations)
  sample_size <- length(observations)
  sample_min <- min(observations)
  sample_max <- max(observations)
  
  sample_median <- median(observations)
  
  std_err <- sample_sd/ sqrt(sample_size)
  
  lower_bound <- sample_mean - (z_score * std_err)
  upper_bound <- sample_mean + (z_score * std_err)
  
  
  return(list("lower_bound" = lower_bound,
              "mean" = sample_mean,
              "upper_bound" = upper_bound,
              "min" = sample_min,
              "max" = sample_max))
}
```

```{r sandbox}
filter(EVSE_util_wkday, !is.na("utilization"))

undebug(Get_CI)
Weekday.CI <- Get_CI(EVSE_util_wkday)
```


```{r weedays}
EVSE_util_wkday <- EVSE_util_lowP %>%
  filter(weekday <= 5)


#get the confidence interval for each hour
for(h in 0:23) {
  this.df <- Subset_EVSE(EVSE_util_wkday, hour.f = h)
  
  this.CI <- Get_CI(this.df)
  
  result.df <- data.frame(hour = h, 
                          lower_bound = this.CI$lower_bound,
                          mean = this.CI$mean,
                          upper_bound = this.CI$upper_bound,
                          min = this.CI$min,
                          max = this.CI$max)
  
  if(h == 0) {
    result <- result.df
  } else {
    result <- rbind(result, result.df)
    }
}

#visualizations
result

plot(x = EVSE_util_wkday$hour, y = EVSE_util_wkday$utilization*100, 
     ylim = c(0,20), ylab = "Utilization [%]", xlab = "Hour", 
     col = 'black', pch = 19, cex = 0.8)

plot(result$hour, result$mean*100, type = 'l', col = 'black', 
     xlab = "hour", ylab = "utilization [%]", ylim = c(0,20),
     main = "Weekdays")
lines(result$hour, result$lower_bound*100, type = 'l', col = 'blue')
lines(result$hour, result$upper_bound*100, type = 'l', col = 'blue')
lines(result$hour, result$min*100, type = 'l', col = 'red')
lines(result$hour, result$max*100, type = 'l', col = 'red')

```
```{r}
hist(filter(result, hour = 10))
```

```{r clean data}
EVSE_util_df_cleaned <- EVSE_util_df %>%
  filter(unknown < dim(EVSE_util_df)[1] * 0.1) %>% #remove instances where 'unknown' CPs are too high, this is likely a data collection error
  merge(Charger_df, Status_df, by = "EvseID", all = TRUE)

```

```{r plot utilization}
plot(x = as.POSIXlt(EVSE_util_df_cleaned$timestamp), y = EVSE_util_df_cleaned$utilization, pch = 19,
     ylab = "Utilization Rate", xlab = "Date", ylim = c(0,0.25))

```


```{r filter for observations}

status_filter <- function(data, )

```

```{r EVSE details}

Power_demand <- function(Charger_df, Status_df) {
  Charger_df <- Charger_df %>%
    select(EvseID, Power_kW)
  
  # Add the power demand column to the status data frame
  Power_status_df <- merge(Charger_df, Status_df, by = "EvseID", all = TRUE)
  
  # convert "occupied" into the power level for all the status columns
 for(col in 3:dim(Power_status_df)[2]) {
   Power_status_df[ , col] <- Power_status_df[ , "Power_kW"] * as.numeric(Power_status_df[ , col] == "Occupied")
 }
  return(Power_status_df) 
}

```

```{r convert statuses into power level demands}
EVSE_df <- Power_demand(CH_EVSE_details_short, EVSE_partial.B)
```


```{r clean power status}
Power_status_df_cleaned <- Power_status_df %>%
  filter(!is.na(Power_kW))
```


```{r power level}
Power_level <- function(df_input, filters = NULL) { #takes the df object from function "Power_demand()" as the input
  df_power <- data.frame(timestamp = NA, year = NA, month = NA, day = NA, weekday = NA, hour = NA, minute = NA, power = NA)
  for(col in colnames(df_input[-c(1:2)])) {
    power_dem <- sum(df_input[ , col], na.rm = TRUE) #gets the total power level
    
    #convert column name to a datetime object
    datetime_string <- sub("S_","",col)
    datetime_object <- ymd_hms(gsub("\\.", ":", datetime_string), tz = "Europe/Zurich")
    
    #record the data in a new results dataframe
    row_pwr <- data.frame(timestamp = datetime_object,
                           year = year(datetime_object), 
                           month = month(datetime_object),
                           day = day(datetime_object),
                           weekday = wday(datetime_object),
                           hour = hour(datetime_object),
                           minute = round(minute(datetime_object)/5)*5,
                           power = power_dem)
    
    #bind with the large df
    df_power <- rbind(df_power, row_pwr)
  }
  return(df_power)
}

```

```{r power level data}
#takes time to run
Power_results <- Power_level(Power_status_df_cleaned)
```
```{r power level data cleaned}
Power_results_cleaned <- Power_results %>%
  filter(power > 0)

```


```{r plot power}
plot(x = as.POSIXlt(Power_results_cleaned$timestamp), y = Power_results_cleaned$power/1000, pch = 19,
     ylab = "Power Demand [MW]", xlab = "Date", ylim = c(0,20))
```

